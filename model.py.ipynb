{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils import load_data\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import keras\n",
    "import numpy as np\n",
    "## Keras\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data(test_size=0.25)\n",
    "\n",
    "\"\"\"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_y_1 = LabelEncoder()\n",
    "y_train = labelencoder_y_1.fit_transform(y_train)\"\"\"\n",
    "# print some details\n",
    "# number of samples in training data\n",
    "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of testing samples:\", X_test.shape[0])\n",
    "# number of features used\n",
    "# this is a vector of features extracted \n",
    "# using utils.extract_features() method\n",
    "print(\"[+] Number of features:\", X_train.shape[1])\n",
    "# best model, determined by a grid search\n",
    "model_params = {\n",
    "    'alpha': 0.01,\n",
    "    'batch_size': 256,\n",
    "    'epsilon': 1e-08, \n",
    "    'hidden_layer_sizes': (300,), \n",
    "    'learning_rate': 'adaptive', \n",
    "    'max_iter': 500, \n",
    "}\n",
    "# initialize Multi Layer Perceptron classifier\n",
    "# with best parameters ( so far )\n",
    "#model = MLPClassifier(**model_params)\n",
    "\n",
    "# train the model\n",
    "print(\"[*] Training the model...\")\n",
    "#model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "lb = LabelEncoder()\n",
    "'''y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))'''\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "\"\"\"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_y_1 = LabelEncoder()\n",
    "y_train = labelencoder_y_1.fit_transform(y_train)\n",
    "\n",
    "labelencoder_y_2 = LabelEncoder()\n",
    "y_test = labelencoder_y_1.fit_transform(y_test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, padding='same',input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(128, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(256, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(LSTM(units=128, return_sequences = True)) \n",
    "model.add(Flatten())\n",
    "#adding Lstm\n",
    "\n",
    "# Edit according to target class no.\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "opt = 'adam'\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=16, epochs=50, validation_data=(X_test, y_test))\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "# predict 25% of data to measure how good we are\n",
    "#y_pred = model.predict(X_test)\n",
    "\n",
    "rounded_labels=np.argmax(y_test, axis=1)\n",
    "rounded_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(rounded_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we save the model\n",
    "# make result directory if doesn't exist yet\n",
    "if not os.path.isdir(\"result\"):\n",
    "    os.mkdir(\"result\")\n",
    "\n",
    "pickle.dump(model, open(\"result/mlp_classifier.model\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
